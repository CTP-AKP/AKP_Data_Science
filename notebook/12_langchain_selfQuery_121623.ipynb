{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3cff1cf",
   "metadata": {},
   "source": [
    "## 0.0 LangChain - Self-querying\n",
    "- I followed through the LangChain course on deep learning ai\n",
    "- https://learn.deeplearning.ai/langchain-chat-with-your-data/lesson/4/vectorstores-and-embedding\n",
    "\n",
    "### 0.1 Reference\n",
    "- another reference is Langchain tutorial on Self-querying\n",
    "- \n",
    "https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47874e81",
   "metadata": {},
   "source": [
    "### 1.0 Dataframe\n",
    "- import .csv that stores 2 columns\n",
    "    - ```name```: game names that exist in our dataset from Kaggle \n",
    "    - ```content```: text description that was scraped from Wikipedia\n",
    "- wiki scraper is also on our Github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "487a0bbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f1fac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    140 (one hundred [and] forty) is the natural n...\n",
      "Name: content, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>140 (one hundred [and] forty) is the natural n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60 Seconds!</td>\n",
       "      <td>60 Seconds! is an action-adventure video game ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7 Days to Die</td>\n",
       "      <td>7 Days to Die is a survival horror video game ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>911 Operator</td>\n",
       "      <td>A dispatcher is a communications worker who re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Hat in Time</td>\n",
       "      <td>A Hat in Time is a platform game developed by ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name                                            content\n",
       "0            140  140 (one hundred [and] forty) is the natural n...\n",
       "1    60 Seconds!  60 Seconds! is an action-adventure video game ...\n",
       "2  7 Days to Die  7 Days to Die is a survival horror video game ...\n",
       "3   911 Operator  A dispatcher is a communications worker who re...\n",
       "4  A Hat in Time  A Hat in Time is a platform game developed by ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv as Dataframe\n",
    "df = pd.read_csv('../data/name_content_plot.csv')\n",
    "df.dtypes\n",
    "print(df.head(1)['content'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691ac2f1",
   "metadata": {},
   "source": [
    "### 1.1 Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d25034",
   "metadata": {},
   "source": [
    "Can only select 1 column for embedding!!!!\n",
    "- ```page_content_column```\n",
    "- all remaing columns from dataset will be store as ```metadata```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc66558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DataFrameLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13339fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are different data loader, as well as CSV loader\n",
    "# but dataframe loader worked on our file\n",
    "loader = DataFrameLoader(df, page_content_column=\"content\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9d6efba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: Albion Online (AO) is a free medieval fantasy MMORPG developed by Sandbox Interactive, a studio based in Berlin, Germany.Set in a medieval world, Albion Online is a medieval fantasy game based on the Arthurian legends, with militaristic strategy aspects to it. Albion Online has been translated into 11 languages and has over 5 million registered users.\n",
      "\n",
      "\n",
      "== Gameplay ==\n",
      "Albion Online's gameplay centres itself around a classless system, in which the equipment a player chooses to wear defines their abilities and the way they can play. Players can go out and do activities in Albion's world in order to gain \"Fame,\" similar to \"experience\" in other MMORPGs. Through this Fame players can get access to other weapon and armour types, with stronger equipment requiring more Fame to use. Stronger gear can be used as players progress throughout the game.\n",
      "The game has a large open-world map that players can travel through. Different PVP zones offer different levels of risk and reward, including Yellow, Red, and Black zones; Red and Black zones featuring full loot drop upon death. \n",
      "The game has a fully player driven economy. All equipment and items are made by other players. The game offers both PVE and PVP experience.\n",
      "\n",
      "\n",
      "== Development ==\n",
      "During the beta stages of development, players were able to purchase \"Founder's Packs\" to gain access to the closed beta play-tests which were run intermittently by Sandbox Interactive, typically after an interval of a few months of development. After the release of the game, these founder's packs were made unavailable for purchase. Albion Online removed its free-to-play model for various reasons on December 30, 2015. (Which was then made free again at a later date) When it initially released on July 17, 2017, Albion Online offered a selection of \"Starter Packs\" which granted players access to the game and offered a varying amount of gold (In-game currency) to get started. Once a player purchased any of the starter packs, they would be granted open-ended access to the game with no extra mandatory fees. Players could also purchase membership for a limited amount of time without the benefits of the starter packs. On April 10, 2019, Albion Online went Free to Play. Players can also buy premium with in-game currency (gold & silver).\n",
      "On March 20, 2023 a second server based in Singapore named \"the east server\" was opened to the public  \n",
      "\n",
      "\n",
      "== References ==\n",
      "\n",
      "\n",
      "== External links ==\n",
      "Official website \n",
      "Official wiki\n",
      "Game Name Albion Online\n"
     ]
    }
   ],
   "source": [
    "# each page is a piece of game description\n",
    "# metadata is the gamename\n",
    "page = pages[22]\n",
    "print('Content:', page.page_content)\n",
    "print('Game Name', page.metadata['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac67cc2",
   "metadata": {},
   "source": [
    "### 2.0 Creating Document with Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93c076f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ac9f7",
   "metadata": {},
   "source": [
    "#### 2.1 TokenTextSplitter\n",
    "- split uppon tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37d2cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting chunks in every 10 tokens\n",
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bb9c3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721\n",
      "200761\n"
     ]
    }
   ],
   "source": [
    "# Original size of page\n",
    "print(len(pages))\n",
    "# Size of documents after splitting them 10 tokens\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af222450",
   "metadata": {},
   "source": [
    "#### 2.2 RecursiveCharacterTextSplitter\n",
    "- split upon punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fa660c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in chunks in sentences\n",
    "# recursive splitter\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\",\", \"(?<=\\. )\", \"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "r_docs = r_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9dccaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721\n",
      "93091\n",
      "page_content=', which makes it a square pyramidal number.' metadata={'name': '140'}\n",
      "{'name': '140'}\n"
     ]
    }
   ],
   "source": [
    "# Original size of page\n",
    "print(len(pages))\n",
    "# Size of documents after splitting them in senteces\n",
    "print(len(r_docs))\n",
    "\n",
    "\n",
    "# a doc example\n",
    "print(r_docs[2])\n",
    "print(r_docs[2].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddc5d4d",
   "metadata": {},
   "source": [
    "### 3.0 Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d0e629",
   "metadata": {},
   "source": [
    "#### 3.1 Choosing Embedding Function \n",
    "#### 3.1.1 Sentence Transformer Embedding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05514b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "embedding_st = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b7d4ab",
   "metadata": {},
   "source": [
    "#### 3.1.2 Open Embedding Function (api key required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "019c2e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "os.environ['OPENAI_API_KEY'] = 'your_api_key'\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding_oa = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bbaa9b",
   "metadata": {},
   "source": [
    "## 4.0 Creating Chromadb Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d355a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Windows user\n",
    "# installing necessary package\n",
    "%%cmd\n",
    "pip install lark chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d377f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50139d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For windows user\n",
    "# cleaning if there is an existing directory\n",
    "%%cmd\n",
    "rmdir -rf ../data/docs/chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b6a9363",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = '../data/docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fd5d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# may take more than 1 hour of embedding\n",
    "db = Chroma.from_documents(\n",
    "    documents=r_docs,\n",
    "    embedding=embedding_oa,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc7f31",
   "metadata": {},
   "source": [
    "### 4.1 Loading an Embedded Chormadb\n",
    "- should choose the same function that was used for embedding\n",
    "- otherwise may encounter error of ```Embedding dimension does not match collection dimensionality```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2e21a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After created a local database, can load it from disk in the future \n",
    "# load from disk\n",
    "db_load = Chroma(\n",
    "    persist_directory=\"../data/docs/chroma_plot\", \n",
    "    embedding_function=embedding_oa\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ce101",
   "metadata": {},
   "source": [
    "### 4.1 Query with Similar Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6343126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"What game is similar to Counter-Strike:global offensive?\"\n",
    "query = \"Which 2 games is similar to CSGO?\"\n",
    "# query = \"What game has animals?\"\n",
    "# query = \"What is a game similar to CSGO, besides CSGO\"\n",
    "# query = \"What is a game similar to CSGO?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a93710f",
   "metadata": {},
   "source": [
    "user can adjust ```k``` manually to receive more docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0262a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{'name': 'Counter-Strike Nexon: Studio'}\n",
      "{'name': 'Counter-Strike'}\n",
      "{'name': 'DayZ'}\n"
     ]
    }
   ],
   "source": [
    "docs = db_load.similarity_search(query, k=3)\n",
    "print(len(docs))\n",
    "for index in range(len(docs)):\n",
    "    print(docs[index].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d1705",
   "metadata": {},
   "source": [
    "### 4.1 Query with Max Marginal Relevence Search\n",
    "2 hyperparameters\n",
    "- user to can adjust ```fetch_k=10``` to get a list of 10 docs\n",
    "- then MMR will output a list of ```k``` docs\n",
    "- with the widest variety of answer\n",
    "    \n",
    "\n",
    "a better version of similarity search\n",
    "* so we can avoid having repeated games or games from the same series!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce240e67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidDimensionException",
     "evalue": "Embedding dimension 384 does not match collection dimensionality 1536",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidDimensionException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m docs \u001b[38;5;241m=\u001b[39m db_load\u001b[38;5;241m.\u001b[39mmax_marginal_relevance_search(query,k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, fetch_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(docs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(docs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmetadata)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py:554\u001b[0m, in \u001b[0;36mChroma.max_marginal_relevance_search\u001b[1;34m(self, query, k, fetch_k, lambda_mult, filter, where_document, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor MMR search, you must specify an embedding function on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    551\u001b[0m     )\n\u001b[0;32m    553\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[1;32m--> 554\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_marginal_relevance_search_by_vector(\n\u001b[0;32m    555\u001b[0m     embedding,\n\u001b[0;32m    556\u001b[0m     k,\n\u001b[0;32m    557\u001b[0m     fetch_k,\n\u001b[0;32m    558\u001b[0m     lambda_mult\u001b[38;5;241m=\u001b[39mlambda_mult,\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m,\n\u001b[0;32m    560\u001b[0m     where_document\u001b[38;5;241m=\u001b[39mwhere_document,\n\u001b[0;32m    561\u001b[0m )\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py:502\u001b[0m, in \u001b[0;36mChroma.max_marginal_relevance_search_by_vector\u001b[1;34m(self, embedding, k, fetch_k, lambda_mult, filter, where_document, **kwargs)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax_marginal_relevance_search_by_vector\u001b[39m(\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    476\u001b[0m     embedding: List[\u001b[38;5;28mfloat\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    483\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs selected using the maximal marginal relevance.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;124;03m    Maximal marginal relevance optimizes for similarity to query AND diversity\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03m    among selected documents.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;124;03m        List of Documents selected by maximal marginal relevance.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__query_collection(\n\u001b[0;32m    503\u001b[0m         query_embeddings\u001b[38;5;241m=\u001b[39membedding,\n\u001b[0;32m    504\u001b[0m         n_results\u001b[38;5;241m=\u001b[39mfetch_k,\n\u001b[0;32m    505\u001b[0m         where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m,\n\u001b[0;32m    506\u001b[0m         where_document\u001b[38;5;241m=\u001b[39mwhere_document,\n\u001b[0;32m    507\u001b[0m         include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistances\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    508\u001b[0m     )\n\u001b[0;32m    509\u001b[0m     mmr_selected \u001b[38;5;241m=\u001b[39m maximal_marginal_relevance(\n\u001b[0;32m    510\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(embedding, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[0;32m    511\u001b[0m         results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    512\u001b[0m         k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    513\u001b[0m         lambda_mult\u001b[38;5;241m=\u001b[39mlambda_mult,\n\u001b[0;32m    514\u001b[0m     )\n\u001b[0;32m    516\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m _results_to_docs(results)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\utils\\utils.py:35\u001b[0m, in \u001b[0;36mxor_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m     invalid_group_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(arg_groups[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m invalid_groups]\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExactly one argument in each of the following\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m groups must be defined:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(invalid_group_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m     )\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py:155\u001b[0m, in \u001b[0;36mChroma.__query_collection\u001b[1;34m(self, query_texts, query_embeddings, n_results, where, where_document, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import chromadb python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install chromadb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection\u001b[38;5;241m.\u001b[39mquery(\n\u001b[0;32m    156\u001b[0m     query_texts\u001b[38;5;241m=\u001b[39mquery_texts,\n\u001b[0;32m    157\u001b[0m     query_embeddings\u001b[38;5;241m=\u001b[39mquery_embeddings,\n\u001b[0;32m    158\u001b[0m     n_results\u001b[38;5;241m=\u001b[39mn_results,\n\u001b[0;32m    159\u001b[0m     where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[0;32m    160\u001b[0m     where_document\u001b[38;5;241m=\u001b[39mwhere_document,\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    162\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:330\u001b[0m, in \u001b[0;36mCollection.query\u001b[1;34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m include \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m include:\n\u001b[0;32m    328\u001b[0m     valid_include\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 330\u001b[0m query_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_query(\n\u001b[0;32m    331\u001b[0m     collection_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    332\u001b[0m     query_embeddings\u001b[38;5;241m=\u001b[39mvalid_query_embeddings,\n\u001b[0;32m    333\u001b[0m     n_results\u001b[38;5;241m=\u001b[39mvalid_n_results,\n\u001b[0;32m    334\u001b[0m     where\u001b[38;5;241m=\u001b[39mvalid_where,\n\u001b[0;32m    335\u001b[0m     where_document\u001b[38;5;241m=\u001b[39mvalid_where_document,\n\u001b[0;32m    336\u001b[0m     include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[0;32m    337\u001b[0m )\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m include\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m query_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    343\u001b[0m ):\n\u001b[0;32m    344\u001b[0m     query_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_loader(uris) \u001b[38;5;28;01mfor\u001b[39;00m uris \u001b[38;5;129;01min\u001b[39;00m query_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    346\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\api\\segment.py:657\u001b[0m, in \u001b[0;36mSegmentAPI._query\u001b[1;34m(self, collection_id, query_embeddings, n_results, where, where_document, include)\u001b[0m\n\u001b[0;32m    655\u001b[0m coll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_collection(collection_id)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m query_embeddings:\n\u001b[1;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dimension(coll, \u001b[38;5;28mlen\u001b[39m(embedding), update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    659\u001b[0m metadata_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mget_segment(collection_id, MetadataReader)\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mor\u001b[39;00m where_document:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\api\\segment.py:797\u001b[0m, in \u001b[0;36mSegmentAPI._validate_dimension\u001b[1;34m(self, collection, dim, update)\u001b[0m\n\u001b[0;32m    795\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection_cache[\u001b[38;5;28mid\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dim\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m collection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidDimensionException(\n\u001b[0;32m    798\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match collection dimensionality \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    799\u001b[0m     )\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mInvalidDimensionException\u001b[0m: Embedding dimension 384 does not match collection dimensionality 1536"
     ]
    }
   ],
   "source": [
    "# An example of using different embedding function during and embedding and sending query\n",
    "docs = db_load.max_marginal_relevance_search(query,k=3, fetch_k=10)\n",
    "print(docs[0].page_content)\n",
    "print(docs[0].metadata)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "36d73e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "CS:GO.\n",
      "{'name': 'Counter-Strike Nexon: Studio'}\n"
     ]
    }
   ],
   "source": [
    "# Correct Exmaple\n",
    "docs = db_load.max_marginal_relevance_search(query,k=3, fetch_k=10)\n",
    "print(len(docs))\n",
    "print(docs[0].page_content)\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff69278b",
   "metadata": {},
   "source": [
    "## 5.0 Self Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62a6eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f8a737",
   "metadata": {},
   "source": [
    "### 5.1 Selecting LLM \n",
    "- langachain is providing a tons of choice on LLM\n",
    "- such as https://python.langchain.com/docs/integrations/llms/openllm\n",
    "- in this case, we are using ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2080daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0145c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many more llm that \n",
    "from langchain.llms import Cohere, HuggingFaceHub, OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ca0e3",
   "metadata": {},
   "source": [
    "### 5.2 Metadata Field Info\n",
    "```document_content_description```\n",
    "- can provide more information about your query to LLM\n",
    "\n",
    "```metadata_field_info```\n",
    "- provide information about the metadata in our database\n",
    "- Can even specify your value of metadata \n",
    "```python\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genre of the video game. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c31aafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"name\",\n",
    "        description=\"The name of this video game\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "document_content_description = \"Brief summary of a video game\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3c8d7",
   "metadata": {},
   "source": [
    "### 5.3 Setting Up Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23583e3f",
   "metadata": {},
   "source": [
    "#### 5.3.1 Using db itself as retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f10b062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db_load.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8bf19cb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Counter-Strike Nexon: Studio\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(query)\n",
    "print(len(docs))\n",
    "print(docs[0].metadata['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17944f83",
   "metadata": {},
   "source": [
    "#### 5.3.2 Implmenting LLM\n",
    "simply using our previous components\n",
    "- ```enable_limit=True``` allows the LLM to detect value of ```k``` by itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7856ed1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    db_load,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    enable_limit=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d75f87b",
   "metadata": {},
   "source": [
    "### 5.4 Retrieving Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "947c17df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Counter-Strike Nexon: Studio\n",
      "Counter-Strike\n"
     ]
    }
   ],
   "source": [
    "# Able to detect which 2 games from our question\n",
    "docs = retriever.invoke(query)\n",
    "print(len(docs))\n",
    "for doc in docs:print(doc.metadata['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d23e30e",
   "metadata": {},
   "source": [
    "#### 5.4.1 Using Get Relevant Documents\n",
    "to specify our purpose of this query\n",
    "- but they performed the same\n",
    "- maybe because we sent a clear question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e21546d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Counter-Strike Nexon: Studio\n",
      "Counter-Strike\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(query)\n",
    "print(len(docs))\n",
    "for doc in docs:print(doc.metadata['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3557334c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd3d72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3bb81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e3a42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
